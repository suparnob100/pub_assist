{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install arxiv_latex_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install arxiv_latex_cleaner\n",
    "import os\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.popen(\"arxiv_latex_cleaner reassembled_document.tex --keep_bib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code that finds all the dependencies of a latex file and puts all of those along with the latex file in a folder called new_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the name of your .tex file\n",
    "filename = 'reassembled_document.tex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory of the .tex file\n",
    "base_dir = os.path.dirname(os.path.abspath(filename))\n",
    "\n",
    "# Extract graphics path(s) from the .tex file\n",
    "with open(filename, 'r') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patterns\n",
    "# \\includegraphics command with optional arguments captured as group(1)\n",
    "# and filename as group(2)\n",
    "includegraphics_pattern = re.compile(r'(\\\\includegraphics(?:\\[[^\\]]*\\])?)\\{([^}]+)\\}')\n",
    "\n",
    "input_pattern = re.compile(r'\\\\input\\{(.+?)\\}')\n",
    "include_pattern = re.compile(r'\\\\include\\{(.+?)\\}')\n",
    "bibliography_pattern = re.compile(r'\\\\bibliography\\{(.+?)\\}')\n",
    "\n",
    "graphicspath_pattern = re.compile(r'\\\\graphicspath\\{\\{(.+?)\\}\\}')\n",
    "graphics_paths = graphicspath_pattern.findall(content)\n",
    "\n",
    "new_folder = 'new_folder'\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "image_extensions = ['.pdf', '.png', '.jpg', '.jpeg', '.eps']\n",
    "file_map = {}\n",
    "\n",
    "def get_unique_filename(folder, original_basename):\n",
    "    \"\"\"Return a unique filename inside `folder` by appending a counter if needed.\"\"\"\n",
    "    base, ext = os.path.splitext(original_basename)\n",
    "    unique_name = original_basename\n",
    "    count = 1\n",
    "    while os.path.exists(os.path.join(folder, unique_name)):\n",
    "        unique_name = f\"{base}_{count}{ext}\"\n",
    "        count += 1\n",
    "    return unique_name\n",
    "\n",
    "def update_references(content, old_name, new_name):\n",
    "    \"\"\"Update \\ref, \\cref, \\eqref, and \\label commands referencing old_name with new_name.\"\"\"\n",
    "    for cmd in [\"ref\", \"cref\", \"eqref\", \"label\"]:\n",
    "        old_pattern = f\"\\\\{cmd}{{{old_name}}}\"\n",
    "        new_pattern = f\"\\\\{cmd}{{{new_name}}}\"\n",
    "        content = content.replace(old_pattern, new_pattern)\n",
    "    return content\n",
    "\n",
    "def find_file(old_filename):\n",
    "    \"\"\"Try to locate the file referenced by old_filename in base_dir and graphics_paths.\"\"\"\n",
    "    # Check if old_filename has a known extension\n",
    "    has_ext = any(old_filename.endswith(ext) for ext in image_extensions)\n",
    "    candidates = []\n",
    "    if has_ext:\n",
    "        # If it has a known extension, try directly\n",
    "        candidates.append(os.path.join(base_dir, old_filename))\n",
    "        for gpath in graphics_paths:\n",
    "            candidates.append(os.path.join(base_dir, gpath, os.path.basename(old_filename)))\n",
    "    else:\n",
    "        # If no extension, try each image extension\n",
    "        for ext in image_extensions:\n",
    "            candidates.append(os.path.join(base_dir, old_filename + ext))\n",
    "        for gpath in graphics_paths:\n",
    "            for ext in image_extensions:\n",
    "                candidates.append(os.path.join(base_dir, gpath, old_filename + ext))\n",
    "\n",
    "    # Return the first existing file found\n",
    "    for c in candidates:\n",
    "        if os.path.exists(c):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# Process \\includegraphics first to handle optional arguments carefully\n",
    "for m in includegraphics_pattern.findall(content):\n",
    "    prefix = m[0]  # \\includegraphics and optional args\n",
    "    old_filename = m[1]  # the filename inside { }\n",
    "    if old_filename in file_map:\n",
    "        # Already processed this file\n",
    "        new_filename = file_map[old_filename]\n",
    "        content = re.sub(\n",
    "            rf'({re.escape(prefix)})\\{{{re.escape(old_filename)}}}',\n",
    "            rf'\\1{{{new_filename}}}',\n",
    "            content\n",
    "        )\n",
    "        content = update_references(content, old_filename, new_filename)\n",
    "        continue\n",
    "\n",
    "    # Find the file in the filesystem\n",
    "    found_path = find_file(old_filename)\n",
    "    if found_path:\n",
    "        base_filename = os.path.basename(found_path)\n",
    "        unique_filename = get_unique_filename(new_folder, base_filename)\n",
    "        shutil.copy(found_path, os.path.join(new_folder, unique_filename))\n",
    "        file_map[old_filename] = unique_filename\n",
    "\n",
    "        # Replace in content\n",
    "        content = re.sub(\n",
    "            rf'({re.escape(prefix)})\\{{{re.escape(old_filename)}}}',\n",
    "            rf'\\1{{{unique_filename}}}',\n",
    "            content\n",
    "        )\n",
    "        content = update_references(content, old_filename, unique_filename)\n",
    "    else:\n",
    "        print(f\"Image file not found: {old_filename}\")\n",
    "\n",
    "# Process other patterns (\\input, \\include, \\bibliography)\n",
    "# These typically have no optional arguments and don't need special handling\n",
    "for pattern in [input_pattern, include_pattern, bibliography_pattern]:\n",
    "    matches = pattern.findall(content)\n",
    "    for match in matches:\n",
    "        if match in file_map:\n",
    "            # Already processed\n",
    "            new_filename = file_map[match]\n",
    "            content = content.replace(match, new_filename)\n",
    "            content = update_references(content, match, new_filename)\n",
    "            continue\n",
    "\n",
    "        # Bibliography may need extension\n",
    "        is_bib = (pattern == bibliography_pattern and not match.endswith('.bib'))\n",
    "        match_with_ext = match + '.bib' if is_bib else match\n",
    "\n",
    "        found_path = None\n",
    "        # If we are dealing with a bibliography, check with .bib extension\n",
    "        if pattern == bibliography_pattern:\n",
    "            # Try base dir and graphics_paths as well\n",
    "            candidates = [os.path.join(base_dir, match_with_ext)]\n",
    "            for gpath in graphics_paths:\n",
    "                candidates.append(os.path.join(base_dir, gpath, os.path.basename(match_with_ext)))\n",
    "            for c in candidates:\n",
    "                if os.path.exists(c):\n",
    "                    found_path = c\n",
    "                    break\n",
    "        else:\n",
    "            # input/include: just try the file directly\n",
    "            candidates = [os.path.join(base_dir, match),\n",
    "                          os.path.join(base_dir, match_with_ext)]\n",
    "            for gpath in graphics_paths:\n",
    "                candidates.append(os.path.join(base_dir, gpath, os.path.basename(match)))\n",
    "                candidates.append(os.path.join(base_dir, gpath, os.path.basename(match_with_ext)))\n",
    "            for c in candidates:\n",
    "                if os.path.exists(c):\n",
    "                    found_path = c\n",
    "                    break\n",
    "\n",
    "        if found_path:\n",
    "            base_filename = os.path.basename(found_path)\n",
    "            unique_filename = get_unique_filename(new_folder, base_filename)\n",
    "            shutil.copy(found_path, os.path.join(new_folder, unique_filename))\n",
    "            file_map[match] = unique_filename\n",
    "            content = content.replace(match, unique_filename)\n",
    "            content = update_references(content, match, unique_filename)\n",
    "        else:\n",
    "            print(f\"File not found: {match}\")\n",
    "\n",
    "# After all processing, update the \\graphicspath to point only to new_folder\n",
    "content = re.sub(r'\\\\graphicspath\\{\\{.+?\\}\\}', '', content)\n",
    "documentclass_match = re.search(r'(\\\\usepackage{graphicx}.*?\\n)', content)\n",
    "graphicspath_line = '\\\\graphicspath{{' + new_folder + '/}}\\n'\n",
    "if documentclass_match:\n",
    "    insert_pos = documentclass_match.end()\n",
    "    content = content[:insert_pos] + graphicspath_line + content[insert_pos:]\n",
    "else:\n",
    "    # If no \\documentclass found, prepend at the start\n",
    "    content = graphicspath_line + content\n",
    "\n",
    "# Write the modified content\n",
    "with open(filename, 'w', encoding='utf-8') as file:\n",
    "    file.write(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python code to split each section into different tex files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the input file and output directory\n",
    "input_file = 'Manuscript.tex'\n",
    "output_dir = 'sections'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Running the complete Python script again on the newly uploaded file\n",
    "# Resetting variables for the new run\n",
    "# Modifying the script to generate the main.tex file with all the \\include and \\includeonly commands.\n",
    "\n",
    "section_content = []\n",
    "section_files = []\n",
    "preamble_content = ''\n",
    "inside_preamble = True\n",
    "inside_abstract = False\n",
    "outfile = None\n",
    "unmatched_lines = []  # to store lines that seem like sections but are not matched\n",
    "bib_commands = ''  # to store bibliography and bibliography style commands\n",
    "\n",
    "\n",
    "# Handle Abstract\n",
    "begin_abstract_in_line = False\n",
    "end_abstract_in_line = False\n",
    "\n",
    "try:\n",
    "    with open(input_file, 'r') as infile:\n",
    "        for line in infile:\n",
    "            \n",
    "            # Handling Bibliography\n",
    "            bib_match = re.search(r'\\\\bibliography{(.+?)}', line)\n",
    "            bib_filename = bib_match.group(1) if bib_match else None\n",
    "            if bib_filename:\n",
    "                bib_commands += f\"\\\\bibliography{{{bib_filename}}}\\n\"\n",
    "\n",
    "            # Handling Bibliography Style\n",
    "            bibstyle_match = re.search(r'\\\\bibliographystyle{(.+?)}', line)\n",
    "            bibstyle_filename = bibstyle_match.group(1) if bibstyle_match else None\n",
    "            if bibstyle_filename:\n",
    "                bib_commands += f\"\\\\bibliographystyle{{{bibstyle_filename}}}\\n\"\n",
    "            \n",
    "            if '\\\\begin{abstract}' in line:\n",
    "                inside_abstract = True\n",
    "                begin_abstract_in_line = True\n",
    "                output_file = 'abstract'\n",
    "                if outfile:\n",
    "                    outfile.close()\n",
    "                    outfile = None\n",
    "                output_file_path = os.path.join(output_dir, f'{output_file}.tex')\n",
    "                outfile = open(output_file_path, 'w')\n",
    "                continue\n",
    "\n",
    "            if '\\\\end{abstract}' in line:\n",
    "                inside_abstract = False\n",
    "                end_abstract_in_line = True\n",
    "                if outfile:\n",
    "                    outfile.write('\\n\\\\end{abstract}')\n",
    "                    outfile.close()\n",
    "                    outfile = None\n",
    "                section_content.append(f\"\\\\include{{sections/{output_file}}}\")\n",
    "                section_files.append(f\"sections/{output_file}\")\n",
    "                continue\n",
    "\n",
    "            # Handle other sections or appendices\n",
    "            match = re.match(r'\\\\(section\\*?|appendix|preamble)\\{(.+?)\\}', line)\n",
    "            if line.strip() == '\\\\begin{document}':\n",
    "                inside_preamble = False\n",
    "            elif inside_preamble:\n",
    "                preamble_content += line\n",
    "            elif match or line.strip() in ['\\\\end{document}']:\n",
    "                if outfile:\n",
    "                    outfile.close()\n",
    "                    outfile = None\n",
    "                \n",
    "                if line.strip() == '\\\\end{document}':\n",
    "                    break\n",
    "                output_file = match.group(2).strip().replace(\" \", \"_\") if match else None\n",
    "                if output_file:  # Ensuring output_file is not None or empty\n",
    "                    output_file_path = os.path.join(output_dir, f'{output_file}.tex')\n",
    "                    outfile = open(output_file_path, 'w')\n",
    "                else:  # Collect unmatched lines that seem like sections\n",
    "                    unmatched_lines.append(line.strip())\n",
    "                \n",
    "                section_content.append(f\"\\\\include{{sections/{output_file}}}\")\n",
    "                section_files.append(f\"sections/{output_file}\")\n",
    "\n",
    "            if outfile and not inside_preamble:\n",
    "                if '\\\\bibliographystyle{' not in line and '\\\\bibliography{' not in line:\n",
    "                    if begin_abstract_in_line:\n",
    "                        outfile.write('\\\\begin{abstract}\\n'+line)\n",
    "                        begin_abstract_in_line = False\n",
    "                    else:\n",
    "                        outfile.write(line)\n",
    "except Exception as e:\n",
    "    error_message = str(e)\n",
    "\n",
    "# After exiting the loop, close the last outfile if it is open\n",
    "if outfile:\n",
    "    outfile.close()\n",
    "\n",
    "# Writing \\include for all section files\n",
    "all_sections_content = '\\n'.join([\"\\\\include{\"+f\"{itr}\"+\"}\" for itr in section_files])\n",
    "\n",
    "# Add \\includeonly to the preamble\n",
    "preamble_content = preamble_content.split('\\\\begin{document}')[0]  # Removing everything after \\begin{document}\n",
    "preamble_content += '\\n\\\\includeonly{'\n",
    "preamble_content += '\\n'.join([f\"{itr},\" for itr in section_files[:-1]])\n",
    "preamble_content += '\\n'+f\"{section_files[-1]}\"\n",
    "preamble_content += \"\\n\"+\"}\"+\"\\n\"\n",
    "\n",
    "\n",
    "preamble_content += '\\\\begin{document}\\n\\\\maketitle\\n'+'\\\\begingroup\\n\\let\\clearpage\\\\relax'\n",
    "\n",
    "# Write the main file\n",
    "new_main_file_path = 'main3.tex'\n",
    "main_file_content = preamble_content + \"\\n\\n\" + all_sections_content +'\\n\\\\endgroup' +f\"\\n{bib_commands}\" + \"\\n\\\\end{document}\"\n",
    "\n",
    "# Writing the main file content to main.tex in the correct directory\n",
    "with open(new_main_file_path, 'w') as main_file:\n",
    "    main_file.write(main_file_content)\n",
    "\n",
    "# Reading the content of the main.tex file again to verify the corrections\n",
    "with open(new_main_file_path, 'r') as main_file:\n",
    "    corrected_new_main_file_content = main_file.read()\n",
    "\n",
    "# Displaying the corrected main file content\n",
    "corrected_new_main_file_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Every sentence in a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_latex_file(input_filepath: str, output_filepath: str):\n",
    "#     with open(input_filepath, 'r') as infile:\n",
    "#         latex_content = infile.read()\n",
    "\n",
    "#     # Regular expression to match \\begin{} and \\end{} environments\n",
    "#     env_pattern = re.compile(r'(\\\\begin\\{.*?\\}.*?\\\\end\\{.*?\\})', re.DOTALL)\n",
    "\n",
    "#     # Split content into environments and non-environment text\n",
    "#     chunks = re.split(env_pattern, latex_content)\n",
    "\n",
    "#     # Process only the non-environment text\n",
    "#     processed_chunks = []\n",
    "#     for chunk in chunks:\n",
    "#         if chunk.strip().startswith('\\\\begin'):  # if it's an environment, keep it unchanged\n",
    "#             processed_chunks.append(chunk)\n",
    "#         else:  # otherwise, split into sentences and join with newlines\n",
    "#             sentences = re.split(r'(?<=\\.)\\s', chunk)\n",
    "#             processed_chunks.append('\\n'.join(sentences))\n",
    "\n",
    "#     # Join the processed chunks\n",
    "#     processed_content = ''.join(processed_chunks)\n",
    "\n",
    "#     # Write the processed content to the output file\n",
    "#     with open(output_filepath, 'w') as outfile:\n",
    "#         outfile.write(processed_content)\n",
    "\n",
    "\n",
    "# def process_all_tex_files(root_dir: str, output_dir: str):\n",
    "#     for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "#         for filename in filenames:\n",
    "#             if filename.endswith('.tex') and \"_processed\" not in filename:\n",
    "#                 input_filepath = os.path.join(dirpath, filename)\n",
    "#                 output_filepath = os.path.join(output_dir, filename.replace('.tex', '_processed.tex'))\n",
    "#                 process_latex_file(input_filepath, output_filepath)\n",
    "\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# root_dir = r\"D:\\OneDrive - Texas A&M University\\Academic\\Acads IITK\\Paper\\SB\\Experimental_damping_estimation_SB_v4\\Experimental_damping_estimation_SB_AC_v1\" # replace with the path to your .tex files\n",
    "# output_dir = root_dir#'output'  # replace with the path where you want to save processed files\n",
    "# process_all_tex_files(root_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_latex_file(input_filepath: str, output_filepath: str):\n",
    "    with open(input_filepath, 'r', encoding='utf-8') as infile:\n",
    "        latex_content = infile.read()\n",
    "\n",
    "    # Regex pattern to detect LaTeX environments\n",
    "    env_pattern = re.compile(r'(\\\\begin\\{.*?\\}.*?\\\\end\\{.*?\\})', re.DOTALL)\n",
    "\n",
    "    # Split content into environment and non-environment parts\n",
    "    chunks = re.split(env_pattern, latex_content)\n",
    "\n",
    "    processed_chunks = []\n",
    "    for chunk in chunks:\n",
    "        # If this chunk starts with '\\begin', it is an environment; leave it unchanged\n",
    "        if chunk.strip().startswith('\\\\begin'):\n",
    "            processed_chunks.append(chunk)\n",
    "        else:\n",
    "            # Non-environment text\n",
    "            lines = chunk.split('\\n')\n",
    "            processed_lines = []\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    # Preserve blank lines\n",
    "                    processed_lines.append('')\n",
    "                    continue\n",
    "\n",
    "                # Split line into sentences by a period followed by whitespace\n",
    "                sentences = re.split(r'(?<=\\.)\\s', line)\n",
    "                # If there's more than one sentence, join them with newlines\n",
    "                # If only one sentence, leave it as is\n",
    "                if len(sentences) > 1:\n",
    "                    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "                    processed_line = '\\n'.join(sentences)\n",
    "                else:\n",
    "                    processed_line = line\n",
    "\n",
    "                processed_lines.append(processed_line)\n",
    "\n",
    "            # Join the processed lines back together with newlines\n",
    "            processed_chunk = '\\n'.join(processed_lines)\n",
    "            processed_chunks.append(processed_chunk)\n",
    "\n",
    "    # Join all chunks together\n",
    "    processed_content = ''.join(processed_chunks)\n",
    "\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(processed_content)\n",
    "\n",
    "\n",
    "def process_all_tex_files(root_dir: str, output_dir: str):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.tex') and \"_processed\" not in filename:\n",
    "                input_filepath = os.path.join(dirpath, filename)\n",
    "                output_filepath = os.path.join(output_dir, filename.replace('.tex', '_processed.tex'))\n",
    "                process_latex_file(input_filepath, output_filepath)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "root_dir = r\"D:\\OneDrive - Texas A&M University\\Academic\\Acads IITK\\Paper\\SB\\Experimental_damping_estimation_SB_v4\\Experimental_damping_estimation_SB_AC_v1\"\n",
    "output_dir =root_dir\n",
    "process_all_tex_files(root_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# for %f in (*.tex) do latexindent \"%f\" > \"%~nf_indented.tex\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reassemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files and directories\n",
    "main_file_path = 'Main.tex'\n",
    "sections_dir = 'Sections'\n",
    "\n",
    "# Output file\n",
    "output_file_path = 'reassembled_document.tex'\n",
    "\n",
    "# Open the main file and read its content\n",
    "with open(main_file_path, 'r') as main_file:\n",
    "    main_content = main_file.read()\n",
    "\n",
    "\n",
    "# Function to replace \\include*{filename} with the content of the file\n",
    "def replacer(match):\n",
    "    filename = match.group(1)  # Get the filename from the regex match\n",
    "    filepath = f\"{filename}.tex\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Use a regex to find all \\include*{filename} commands and replace them\n",
    "replaced_content = re.sub(r'\\\\include\\{(.+?)\\}', replacer, main_content)\n",
    "replaced_content = re.sub(r'\\\\includeonly\\{.*?\\}', '', replaced_content, flags=re.DOTALL)\n",
    "\n",
    "# Write the replaced content to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.write(replaced_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One last time look over the figures, equations, tables carefully. Generate a latex file that has all these. Check them separately. If needed, mark changes in the PDF and then again change them in the tex file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_environments(latex_code, environments):\n",
    "    \"\"\"\n",
    "    Extract specified environments from the LaTeX code.\n",
    "\n",
    "    :param latex_code: A string containing raw LaTeX code.\n",
    "    :param environments: A list of environment names to extract.\n",
    "    :return: A dictionary with environment names as keys and a list of extracted environments as values.\n",
    "    \"\"\"\n",
    "    extracted = {}\n",
    "    for env in environments:\n",
    "        pattern = re.compile(r'\\\\begin\\{' + env + r'\\}.*?\\\\end\\{' + env + r'\\}', re.DOTALL)\n",
    "        extracted[env] = re.findall(pattern, latex_code)\n",
    "\n",
    "    return extracted\n",
    "\n",
    "def write_to_new_file(extracted, output_filename):\n",
    "    \"\"\"\n",
    "    Write the extracted code to a new LaTeX file with a basic preamble.\n",
    "\n",
    "    :param extracted: A dictionary with extracted environments.\n",
    "    :param output_filename: The name of the output file.\n",
    "    \"\"\"\n",
    "    preamble = \"\"\"\n",
    "\\\\documentclass{article}\n",
    "\\\\usepackage{amsmath}\n",
    "\\\\usepackage{graphicx}\n",
    "\\\\usepackage{booktabs}\n",
    "\\\\usepackage{caption}\n",
    "\\\\usepackage{subcaption}\n",
    "\\\\begin{document}\n",
    "\"\"\"\n",
    "    postamble = \"\\n\\\\end{document}\"\n",
    "\n",
    "    with open(output_filename, 'w') as f:\n",
    "        f.write(preamble)\n",
    "        for env in extracted:\n",
    "            f.write(f'\\n% Extracted {env} environments\\n')\n",
    "            f.write('\\n\\n'.join(extracted[env]))\n",
    "        f.write(postamble)\n",
    "\n",
    "# Example usage\n",
    "input_filename = 'Paper.tex'\n",
    "output_filename = 'Paper_check.tex'\n",
    "\n",
    "# Read the input LaTeX file\n",
    "with open(input_filename, 'r') as f:\n",
    "    latex_code = f.read()\n",
    "\n",
    "# Extract equation, align, table, and figure environments\n",
    "extracted = extract_environments(latex_code, ['equation', 'align', 'table', 'figure'])\n",
    "\n",
    "# Write the extracted code to a new LaTeX file\n",
    "write_to_new_file(extracted, output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy all the latex style files to a specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_copy_latex_style_files(latex_file, output_folder):\n",
    "    # Regular expression to find \\usepackage{} commands in LaTeX\n",
    "    usepackage_re = re.compile(r'\\\\usepackage\\{([^\\}]+)\\}')\n",
    "    \n",
    "    # Open and read the LaTeX file\n",
    "    with open(latex_file, 'r') as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    # Find all \\usepackage{} commands\n",
    "    packages = usepackage_re.findall(data)\n",
    "    \n",
    "    # Search paths for LaTeX style files\n",
    "    search_paths = ['/usr/local/texlive/2022/texmf-dist/tex/latex/']\n",
    "    \n",
    "    # Find and copy the style files\n",
    "    for package in packages:\n",
    "        found = False\n",
    "        for path in search_paths:\n",
    "            for root, dirs, files in os.walk(path):\n",
    "                if f'{package}.sty' in files:\n",
    "                    shutil.copy(os.path.join(root, f'{package}.sty'), output_folder)\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "        if not found:\n",
    "            print(f\"Warning: Style file for package '{package}' not found.\")\n",
    "            \n",
    "# Example usage:\n",
    "# find_and_copy_latex_style_files('path/to/latex/file.tex', 'path/to/output/folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
